{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7654a7bc",
   "metadata": {},
   "source": [
    "# Sistema desenvolvido por Flayson Santos \n",
    "\n",
    "\n",
    "## ReferÃªncia https://sefiks.com/2020/02/17/face-recognition-with-facebook-deepface-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9dd23ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (63.4.1)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (1.50.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\flayson santos\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9bc1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, LocallyConnected2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import model_from_json\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b61cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass\n",
    "print(\"ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba88874",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (152, 152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "665d89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "opencv_home = cv2.__file__\n",
    "folders = opencv_home.split(os.path.sep)[0:-1]\n",
    "path = folders[0]\n",
    "for folder in folders[1:]:\n",
    "\tpath = path + \"/\" + folder\n",
    "\n",
    "detector_path = path+\"/data/haarcascade_frontalface_alt.xml\"\n",
    "\n",
    "if os.path.isfile(detector_path) != True:\n",
    "\traise ValueError(\"Confirm that opencv is installed on your environment! Expected path \",detector_path,\" violated.\")\n",
    "else:\n",
    "\tface_cascade = cv2.CascadeClassifier(detector_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a3ea4774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFace(img_path, target_size=(152, 152)):\n",
    "\t\n",
    "\timg = cv2.imread(img_path)\n",
    "\t\n",
    "\tfaces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "\tif len(faces) > 0:\n",
    "\t\tx,y,w,h = faces[0]\n",
    "\t\t\n",
    "\t\tmargin = 0\n",
    "\t\tx_margin = w * margin / 100\n",
    "\t\ty_margin = h * margin / 100\n",
    "\t\t\n",
    "\t\tif y - y_margin > 0 and y+h+y_margin < img.shape[1] and x-x_margin > 0 and x+w+x_margin < img.shape[0]:\n",
    "\t\t\tdetected_face = img[int(y-y_margin):int(y+h+y_margin), int(x-x_margin):int(x+w+x_margin)]\n",
    "\t\telse:\n",
    "\t\t\tdetected_face = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "\t\t\n",
    "\t\tdetected_face = cv2.resize(detected_face, target_size)\n",
    "\t\t\n",
    "\t\timg_pixels = image.img_to_array(detected_face)\n",
    "\t\timg_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\t\t\n",
    "\t\t#normalize in [0, 1]\n",
    "\t\timg_pixels /= 255 \n",
    "\t\t\n",
    "\t\treturn img_pixels\n",
    "\telse:\n",
    "\t\traise ValueError(\"Face could not be detected in \", img_path,\". Please confirm that the picture is a face photo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31536331",
   "metadata": {},
   "source": [
    "# Transfer learning dos pesos do modelo ja treinado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de61a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DeepFace model\n",
    "base_model = Sequential()\n",
    "base_model.add(Convolution2D(32, (11, 11), activation='relu', name='C1', input_shape=(152, 152, 3)))\n",
    "base_model.add(MaxPooling2D(pool_size=3, strides=2, padding='same', name='M2'))\n",
    "base_model.add(Convolution2D(16, (9, 9), activation='relu', name='C3'))\n",
    "base_model.add(LocallyConnected2D(16, (9, 9), activation='relu', name='L4'))\n",
    "base_model.add(LocallyConnected2D(16, (7, 7), strides=2, activation='relu', name='L5') )\n",
    "base_model.add(LocallyConnected2D(16, (5, 5), activation='relu', name='L6'))\n",
    "base_model.add(Flatten(name='F0'))\n",
    "base_model.add(Dense(4096, activation='relu', name='F7'))\n",
    "base_model.add(Dropout(rate=0.5, name='D0'))\n",
    "base_model.add(Dense(8631, activation='softmax', name='F8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768e2125",
   "metadata": {},
   "source": [
    "## baixe o arquivo https://github.com/swghosh/DeepFace/releases\n",
    "\n",
    "model.load_weights(\"VGGFace2_DeepFace_weights_val-0.9034.h5\")\n",
    "\n",
    "extraia e passe o caminho do diretrio em base_model.load_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0d5315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok loading model\n"
     ]
    }
   ],
   "source": [
    "base_model.load_weights(\"C:/Users/Flayson Santos/Dio_MachineLearn/machine_learnig/facil_detection_ofc/facial/VGGFace2_DeepFace_weights_val-0.9034.h5/VGGFace2_DeepFace_weights_val-0.9034.h5\")\n",
    "\n",
    "print (\"ok loading model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55145802",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.layers[0].input, outputs=base_model.layers[-3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5268828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_normalize(x):\n",
    "    return x / np.sqrt(np.sum(np.multiply(x, x)))\n",
    " \n",
    "def findEuclideanDistance(source_representation, test_representation):\n",
    "    euclidean_distance = source_representation - test_representation\n",
    "    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
    "    euclidean_distance = np.sqrt(euclidean_distance)\n",
    "    return euclidean_distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02689019",
   "metadata": {},
   "source": [
    "## Base de dados para o treinamento (Voce deve criar uma pasta com arquivos .jpg e passa o caminho da pasta para employee_pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c985eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb64f2b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "employee representations retrieved successfully\n"
     ]
    }
   ],
   "source": [
    "employee_pictures = \"C:/Users/Flayson Santos/Dio_MachineLearn/machine_learnig/facil_detection_ofc/database\"\n",
    "\n",
    "employees = dict()\n",
    "\n",
    "for file in listdir(employee_pictures):\n",
    "    employee, extension = file.split(\".\")\n",
    "    img_path = 'database/%s.jpg' % (employee)\n",
    "    img = detectFace(img_path)\n",
    "    \n",
    "    representation = model.predict(img)[0]\n",
    "    \n",
    "    employees[employee] = representation\n",
    "    \n",
    "print(\"employee representations retrieved successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9b8bb",
   "metadata": {},
   "source": [
    "# Codigo 1 parte reconhecimento facil em imagem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b5ddc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 781ms/step\n",
      "0.34149352\n",
      "0.8434756\n",
      "0.67915505\n",
      "detected:  Elon Musk ( 0.34149352 )\n",
      "1/1 [==============================] - 1s 741ms/step\n",
      "0.7215911\n",
      "0.5451348\n",
      "0.7771144\n",
      "detected:  Flayson Santos ( 0.5451348 )\n",
      "1/1 [==============================] - 1s 799ms/step\n",
      "0.7003709\n",
      "0.9339839\n",
      "0.4386393\n",
      "detected:  linus  trovalds ( 0.4386393 )\n"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/Flayson Santos/Dio_MachineLearn/machine_learnig/facil_detection_ofc/database/\"\n",
    "for infile in glob.glob(os.path.join(path, '*.jpg')):\n",
    "\timg = cv2.imread(infile)\n",
    "\timg = cv2.resize(img, (int(0.5*img.shape[1]), int(0.5*img.shape[0])), interpolation = cv2.INTER_AREA)\n",
    "\tfaces = face_cascade.detectMultiScale(img, 1.2, 5)\n",
    "\t\n",
    "\tfor (x,y,w,h) in faces:\n",
    "\t\tif w > 130: #discard small detected faces\n",
    "\t\t\tcv2.rectangle(img, (x,y), (x+w,y+h), (0, 255, 0), 6) #draw rectangle to main image\n",
    "\t\t\t\n",
    "\t\t\tdetected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "\t\t\tdetected_face = cv2.resize(detected_face, target_size) #resize to 152x152\n",
    "\t\t\t\n",
    "\t\t\timg_pixels = image.img_to_array(detected_face)\n",
    "\t\t\timg_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\t\t\timg_pixels /= 255\n",
    "\t\t\t\n",
    "\t\t\tcaptured_representation = model.predict(img_pixels)[0]\n",
    "\t\t\t\n",
    "\t\t\tdistances = []\n",
    "\t\t\t\n",
    "\t\t\tfor i in employees:\n",
    "\t\t\t\temployee_name = i\n",
    "\t\t\t\tsource_representation = employees[i]\n",
    "\t\t\t\t\n",
    "\t\t\t\tdistance = findEuclideanDistance(l2_normalize(captured_representation), l2_normalize(source_representation))\n",
    "\t\t\t\tdistances.append(distance)\n",
    "\t\t\t\tprint(distance)\n",
    "\t\t\tis_found = False; index = 0\n",
    "\t\t\tfor i in employees:\n",
    "\t\t\t\temployee_name = i\n",
    "\t\t\t\tif index == np.argmin(distances):\n",
    "\t\t\t\t\tif distances[index] <= 0.99:\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tprint(\"detected: \",employee_name, \"(\",distances[index],\")\")\n",
    "\t\t\t\t\t\temployee_name = employee_name.replace(\"_\", \"\")\n",
    "\t\t\t\t\t\tsimilarity = distances[index]\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tis_found = True\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\n",
    "\t\t\t\tindex = index + 1\n",
    "\t\t\t\n",
    "\t\t\tif is_found:\n",
    "\t\t\t\tdisplay_img = cv2.imread(\"database/%s.jpg\" % employee_name)\n",
    "\t\t\t\tpivot_img_size = 112\n",
    "\t\t\t\tdisplay_img = cv2.resize(display_img, (pivot_img_size, pivot_img_size))\n",
    "\t\t\t\t\t\t\t\t\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tresolution_x = img.shape[1]; resolution_y = img.shape[0]\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tlabel = employee_name+\" (\"+\"{0:.2f}\".format(similarity)+\")\"\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tif y - pivot_img_size > 0 and x + w + pivot_img_size < resolution_x:\n",
    "\t\t\t\t\t\t#top right\n",
    "\t\t\t\t\t\timg[y - pivot_img_size:y, x+w:x+w+pivot_img_size] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x+w, y+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#connect face and text\n",
    "\t\t\t\t\t\tcv2.line(img,(x+int(w/2), y), (x+3*int(w/4), y-int(pivot_img_size/2)),(67,67,67),1)\n",
    "\t\t\t\t\t\tcv2.line(img, (x+3*int(w/4), y-int(pivot_img_size/2)), (x+w, y - int(pivot_img_size/2)), (67,67,67),1)\n",
    "\t\t\t\t\telif y + h + pivot_img_size < resolution_y and x - pivot_img_size > 0:\n",
    "\t\t\t\t\t\t#bottom left\n",
    "\t\t\t\t\t\timg[y+h:y+h+pivot_img_size, x-pivot_img_size:x] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x - pivot_img_size, y+h-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#connect face and text\n",
    "\t\t\t\t\t\tcv2.line(img,(x+int(w/2), y+h), (x+int(w/2)-int(w/4), y+h+int(pivot_img_size/2)),(67,67,67),1)\n",
    "\t\t\t\t\t\tcv2.line(img, (x+int(w/2)-int(w/4), y+h+int(pivot_img_size/2)), (x, y+h+int(pivot_img_size/2)), (67,67,67),1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\telif y - pivot_img_size > 0 and x - pivot_img_size > 0:\n",
    "\t\t\t\t\t\t#top left\n",
    "\t\t\t\t\t\timg[y-pivot_img_size:y, x-pivot_img_size:x] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x - pivot_img_size, y+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#connect face and text\n",
    "\t\t\t\t\t\tcv2.line(img,(x+int(w/2), y), (x+int(w/2)-int(w/4), y-int(pivot_img_size/2)),(67,67,67),1)\n",
    "\t\t\t\t\t\tcv2.line(img, (x+int(w/2)-int(w/4), y-int(pivot_img_size/2)), (x, y - int(pivot_img_size/2)), (67,67,67),1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\telif x+w+pivot_img_size < resolution_x and y + h + pivot_img_size < resolution_y:\n",
    "\t\t\t\t\t\t#bottom righ\n",
    "\t\t\t\t\t\timg[y+h:y+h+pivot_img_size, x+w:x+w+pivot_img_size] = display_img\n",
    "\t\t\t\t\t\tcv2.putText(img, label, (x+w, y+h-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#connect face and text\n",
    "\t\t\t\t\t\tcv2.line(img,(x+int(w/2), y+h), (x+int(w/2)+int(w/4), y+h+int(pivot_img_size/2)),(67,67,67),1)\n",
    "\t\t\t\t\t\tcv2.line(img, (x+int(w/2)+int(w/4), y+h+int(pivot_img_size/2)), (x+w, y+h+int(pivot_img_size/2)), (67,67,67),1)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\tprint(\"exception occured: \", str(e))\n",
    "\t\t\t\n",
    "\tcv2.imshow('img',img)\n",
    "\t\n",
    "\tcv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ab09d",
   "metadata": {},
   "source": [
    "# Codigo 2 parte reconhecimento facil em video e webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ffece5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 374ms/step\n",
      "0.9849545\n",
      "0.89767855\n",
      "0.98305994\n",
      "detected:  Flayson Santos ( 0.89767855 )\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "0.9187654\n",
      "0.88787204\n",
      "0.9197352\n",
      "detected:  Flayson Santos ( 0.88787204 )\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "0.93297845\n",
      "0.8052308\n",
      "0.8903655\n",
      "detected:  Flayson Santos ( 0.8052308 )\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "0.8734087\n",
      "0.7821005\n",
      "0.82469434\n",
      "detected:  Flayson Santos ( 0.7821005 )\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "0.92055935\n",
      "0.78465146\n",
      "0.88149256\n",
      "detected:  Flayson Santos ( 0.78465146 )\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "0.8747657\n",
      "0.7747011\n",
      "0.84028345\n",
      "detected:  Flayson Santos ( 0.7747011 )\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "0.92566997\n",
      "0.818605\n",
      "0.8779757\n",
      "detected:  Flayson Santos ( 0.818605 )\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "0.94579184\n",
      "0.8327019\n",
      "0.90442675\n",
      "detected:  Flayson Santos ( 0.8327019 )\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "0.91416746\n",
      "0.80757856\n",
      "0.8725429\n",
      "detected:  Flayson Santos ( 0.80757856 )\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "0.932972\n",
      "0.82229584\n",
      "0.8893707\n",
      "detected:  Flayson Santos ( 0.82229584 )\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "0.9369852\n",
      "0.830578\n",
      "0.90165204\n",
      "detected:  Flayson Santos ( 0.830578 )\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "0.83512014\n",
      "0.7953788\n",
      "0.7743725\n",
      "detected:  linus  trovalds ( 0.7743725 )\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "0.87868327\n",
      "0.7978071\n",
      "0.82749504\n",
      "detected:  Flayson Santos ( 0.7978071 )\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "0.9208273\n",
      "0.80819744\n",
      "0.8771325\n",
      "detected:  Flayson Santos ( 0.80819744 )\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "0.9290486\n",
      "0.8169491\n",
      "0.8858546\n",
      "detected:  Flayson Santos ( 0.8169491 )\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "0.88624954\n",
      "0.7895153\n",
      "0.8371237\n",
      "detected:  Flayson Santos ( 0.7895153 )\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "0.8838706\n",
      "0.8155282\n",
      "0.8257853\n",
      "detected:  Flayson Santos ( 0.8155282 )\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "0.89105237\n",
      "0.80906296\n",
      "0.8761002\n",
      "detected:  Flayson Santos ( 0.80906296 )\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "0.9630862\n",
      "0.82509136\n",
      "0.92615116\n",
      "detected:  Flayson Santos ( 0.82509136 )\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "0.87500393\n",
      "0.88844454\n",
      "0.90723324\n",
      "detected:  Elon Musk ( 0.87500393 )\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "0.88951534\n",
      "0.87306005\n",
      "0.9090083\n",
      "detected:  Flayson Santos ( 0.87306005 )\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "0.88101065\n",
      "0.8986387\n",
      "0.9048779\n",
      "detected:  Elon Musk ( 0.88101065 )\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "0.86256623\n",
      "0.8854797\n",
      "0.8987361\n",
      "detected:  Elon Musk ( 0.86256623 )\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "0.8675573\n",
      "0.8421211\n",
      "0.8899481\n",
      "detected:  Flayson Santos ( 0.8421211 )\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "0.81577826\n",
      "0.8678322\n",
      "0.8526516\n",
      "detected:  Elon Musk ( 0.81577826 )\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "0.8237127\n",
      "0.8592884\n",
      "0.8498886\n",
      "detected:  Elon Musk ( 0.8237127 )\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "0.8432391\n",
      "0.85037416\n",
      "0.8650064\n",
      "detected:  Elon Musk ( 0.8432391 )\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "0.8404118\n",
      "0.8611933\n",
      "0.8638967\n",
      "detected:  Elon Musk ( 0.8404118 )\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "0.8228421\n",
      "0.86171144\n",
      "0.8427038\n",
      "detected:  Elon Musk ( 0.8228421 )\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "0.81163996\n",
      "0.8607472\n",
      "0.8582491\n",
      "detected:  Elon Musk ( 0.81163996 )\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "0.85722125\n",
      "0.8591841\n",
      "0.88056946\n",
      "detected:  Elon Musk ( 0.85722125 )\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "0.8277386\n",
      "0.8610545\n",
      "0.8496755\n",
      "detected:  Elon Musk ( 0.8277386 )\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "0.83975106\n",
      "0.84571\n",
      "0.85686564\n",
      "detected:  Elon Musk ( 0.83975106 )\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "0.8213532\n",
      "0.8658536\n",
      "0.8742422\n",
      "detected:  Elon Musk ( 0.8213532 )\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "0.82577294\n",
      "0.8735461\n",
      "0.873806\n",
      "detected:  Elon Musk ( 0.82577294 )\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "0.8823378\n",
      "0.86679685\n",
      "0.8837781\n",
      "detected:  Flayson Santos ( 0.86679685 )\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "0.8419355\n",
      "0.84913325\n",
      "0.8622102\n",
      "detected:  Elon Musk ( 0.8419355 )\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "0.80671436\n",
      "0.86612487\n",
      "0.86856455\n",
      "detected:  Elon Musk ( 0.80671436 )\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "0.80450207\n",
      "0.8500978\n",
      "0.8361003\n",
      "detected:  Elon Musk ( 0.80450207 )\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "0.81565875\n",
      "0.87169766\n",
      "0.869788\n",
      "detected:  Elon Musk ( 0.81565875 )\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "0.86120236\n",
      "0.8704141\n",
      "0.87118113\n",
      "detected:  Elon Musk ( 0.86120236 )\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "0.8682952\n",
      "0.8667628\n",
      "0.8820698\n",
      "detected:  Flayson Santos ( 0.8667628 )\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "0.8639583\n",
      "0.8575718\n",
      "0.87139666\n",
      "detected:  Flayson Santos ( 0.8575718 )\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "0.85726875\n",
      "0.85383457\n",
      "0.87146086\n",
      "detected:  Flayson Santos ( 0.85383457 )\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "0.87129444\n",
      "0.8704474\n",
      "0.88945097\n",
      "detected:  Flayson Santos ( 0.8704474 )\n",
      "1/1 [==============================] - 0s 425ms/step\n",
      "0.7765079\n",
      "0.8324046\n",
      "0.7994765\n",
      "detected:  Elon Musk ( 0.7765079 )\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "0.76229775\n",
      "0.8400499\n",
      "0.7969056\n",
      "detected:  Elon Musk ( 0.76229775 )\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "0.7691539\n",
      "0.826238\n",
      "0.79050857\n",
      "detected:  Elon Musk ( 0.7691539 )\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "0.758556\n",
      "0.8410025\n",
      "0.7978769\n",
      "detected:  Elon Musk ( 0.758556 )\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "0.7744729\n",
      "0.83959144\n",
      "0.8015008\n",
      "detected:  Elon Musk ( 0.7744729 )\n",
      "1/1 [==============================] - 0s 479ms/step\n",
      "0.79457235\n",
      "0.8524627\n",
      "0.8233059\n",
      "detected:  Elon Musk ( 0.79457235 )\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "0.8528049\n",
      "0.86071616\n",
      "0.8375685\n",
      "detected:  linus  trovalds ( 0.8375685 )\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "0.8195848\n",
      "0.84585506\n",
      "0.84371424\n",
      "detected:  Elon Musk ( 0.8195848 )\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "0.80170137\n",
      "0.84298766\n",
      "0.8323728\n",
      "detected:  Elon Musk ( 0.80170137 )\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "0.89819133\n",
      "0.8747283\n",
      "0.92820865\n",
      "detected:  Flayson Santos ( 0.8747283 )\n",
      "1/1 [==============================] - 0s 494ms/step\n",
      "1.0028393\n",
      "0.8876411\n",
      "1.0121236\n",
      "detected:  Flayson Santos ( 0.8876411 )\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "0.9698598\n",
      "0.8763757\n",
      "0.98813885\n",
      "detected:  Flayson Santos ( 0.8763757 )\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "0.9698817\n",
      "0.8935006\n",
      "0.98056984\n",
      "detected:  Flayson Santos ( 0.8935006 )\n",
      "1/1 [==============================] - 0s 442ms/step\n",
      "0.9181528\n",
      "0.86039823\n",
      "0.9378195\n",
      "detected:  Flayson Santos ( 0.86039823 )\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "0.9238703\n",
      "0.87298536\n",
      "0.9410658\n",
      "detected:  Flayson Santos ( 0.87298536 )\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "0.94374275\n",
      "0.872301\n",
      "0.9509446\n",
      "detected:  Flayson Santos ( 0.872301 )\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "0.9520813\n",
      "0.89163935\n",
      "0.96616226\n",
      "detected:  Flayson Santos ( 0.89163935 )\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "0.932201\n",
      "0.8477967\n",
      "0.9465909\n",
      "detected:  Flayson Santos ( 0.8477967 )\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "0.97080714\n",
      "0.8788011\n",
      "0.9851946\n",
      "detected:  Flayson Santos ( 0.8788011 )\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "0.8916275\n",
      "0.8820132\n",
      "0.89965236\n",
      "detected:  Flayson Santos ( 0.8820132 )\n",
      "1/1 [==============================] - 1s 548ms/step\n",
      "0.84553957\n",
      "0.81216407\n",
      "0.8649433\n",
      "detected:  Flayson Santos ( 0.81216407 )\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "0.9120984\n",
      "0.85484815\n",
      "0.9217644\n",
      "detected:  Flayson Santos ( 0.85484815 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 387ms/step\n",
      "0.97152054\n",
      "0.87666994\n",
      "0.9635755\n",
      "detected:  Flayson Santos ( 0.87666994 )\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "0.87291586\n",
      "0.8449556\n",
      "0.8655888\n",
      "detected:  Flayson Santos ( 0.8449556 )\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "0.9597455\n",
      "0.8850487\n",
      "0.9703835\n",
      "detected:  Flayson Santos ( 0.8850487 )\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "0.8158293\n",
      "0.8422024\n",
      "0.79069906\n",
      "detected:  linus  trovalds ( 0.79069906 )\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "0.75763583\n",
      "0.82443756\n",
      "0.77157116\n",
      "detected:  Elon Musk ( 0.75763583 )\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "0.9576409\n",
      "0.8961097\n",
      "0.9423036\n",
      "detected:  Flayson Santos ( 0.8961097 )\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "0.96143156\n",
      "0.88097036\n",
      "0.947404\n",
      "detected:  Flayson Santos ( 0.88097036 )\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "0.96095985\n",
      "0.8927647\n",
      "0.98381144\n",
      "detected:  Flayson Santos ( 0.8927647 )\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "0.90553564\n",
      "0.85881436\n",
      "0.8863604\n",
      "detected:  Flayson Santos ( 0.85881436 )\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "0.87459385\n",
      "0.8624881\n",
      "0.8562796\n",
      "detected:  linus  trovalds ( 0.8562796 )\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "0.90469295\n",
      "0.90019524\n",
      "0.8712233\n",
      "detected:  linus  trovalds ( 0.8712233 )\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "0.93753374\n",
      "0.896573\n",
      "0.90222126\n",
      "detected:  Flayson Santos ( 0.896573 )\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "0.9158199\n",
      "0.8811694\n",
      "0.89571905\n",
      "detected:  Flayson Santos ( 0.8811694 )\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1.0629476\n",
      "0.9931102\n",
      "1.0560048\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "0.8770101\n",
      "0.9171969\n",
      "0.81767887\n",
      "detected:  linus  trovalds ( 0.81767887 )\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "0.93754303\n",
      "0.87533677\n",
      "0.92786807\n",
      "detected:  Flayson Santos ( 0.87533677 )\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "0.85450536\n",
      "0.81743765\n",
      "0.8599322\n",
      "detected:  Flayson Santos ( 0.81743765 )\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "0.9263284\n",
      "0.84578234\n",
      "0.9290505\n",
      "detected:  Flayson Santos ( 0.84578234 )\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "0.8758011\n",
      "0.8405077\n",
      "0.8814331\n",
      "detected:  Flayson Santos ( 0.8405077 )\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "0.74725187\n",
      "0.9535697\n",
      "0.7709817\n",
      "detected:  Elon Musk ( 0.74725187 )\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "0.6790625\n",
      "0.9317264\n",
      "0.6985702\n",
      "detected:  Elon Musk ( 0.6790625 )\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "0.65621984\n",
      "0.9005248\n",
      "0.6998575\n",
      "detected:  Elon Musk ( 0.65621984 )\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "0.64480144\n",
      "0.90818566\n",
      "0.68816763\n",
      "detected:  Elon Musk ( 0.64480144 )\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "0.6489453\n",
      "0.89594066\n",
      "0.69103366\n",
      "detected:  Elon Musk ( 0.6489453 )\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "0.64695317\n",
      "0.9010002\n",
      "0.6922806\n",
      "detected:  Elon Musk ( 0.64695317 )\n",
      "1/1 [==============================] - 1s 513ms/step\n",
      "0.65861243\n",
      "0.88946223\n",
      "0.68708664\n",
      "detected:  Elon Musk ( 0.65861243 )\n",
      "1/1 [==============================] - 0s 435ms/step\n",
      "0.6488875\n",
      "0.9029185\n",
      "0.69009787\n",
      "detected:  Elon Musk ( 0.6488875 )\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "0.6405686\n",
      "0.89140815\n",
      "0.68551666\n",
      "detected:  Elon Musk ( 0.6405686 )\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "0.6479068\n",
      "0.90279657\n",
      "0.68769884\n",
      "detected:  Elon Musk ( 0.6479068 )\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "0.6534334\n",
      "0.9106804\n",
      "0.6942721\n",
      "detected:  Elon Musk ( 0.6534334 )\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "0.6552505\n",
      "0.9050821\n",
      "0.6779005\n",
      "detected:  Elon Musk ( 0.6552505 )\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "0.64292264\n",
      "0.9017002\n",
      "0.68123645\n",
      "detected:  Elon Musk ( 0.64292264 )\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "0.6546595\n",
      "0.9110593\n",
      "0.69466627\n",
      "detected:  Elon Musk ( 0.6546595 )\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "0.6536429\n",
      "0.8995462\n",
      "0.67691535\n",
      "detected:  Elon Musk ( 0.6536429 )\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "0.6524816\n",
      "0.906948\n",
      "0.6966829\n",
      "detected:  Elon Musk ( 0.6524816 )\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "0.66023165\n",
      "0.92015713\n",
      "0.6967376\n",
      "detected:  Elon Musk ( 0.66023165 )\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "0.6692935\n",
      "0.9336631\n",
      "0.6956531\n",
      "detected:  Elon Musk ( 0.6692935 )\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "0.6521911\n",
      "0.93409044\n",
      "0.71402967\n",
      "detected:  Elon Musk ( 0.6521911 )\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "0.6732259\n",
      "0.9517129\n",
      "0.72765815\n",
      "detected:  Elon Musk ( 0.6732259 )\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "0.6967447\n",
      "0.93037194\n",
      "0.7278356\n",
      "detected:  Elon Musk ( 0.6967447 )\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "0.6503084\n",
      "0.92118\n",
      "0.69969785\n",
      "detected:  Elon Musk ( 0.6503084 )\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "0.653487\n",
      "0.91394717\n",
      "0.687961\n",
      "detected:  Elon Musk ( 0.653487 )\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "0.6561232\n",
      "0.9231308\n",
      "0.70235056\n",
      "detected:  Elon Musk ( 0.6561232 )\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "0.6747927\n",
      "0.9487094\n",
      "0.7081311\n",
      "detected:  Elon Musk ( 0.6747927 )\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "0.6782305\n",
      "0.94622827\n",
      "0.71419334\n",
      "detected:  Elon Musk ( 0.6782305 )\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "0.6643489\n",
      "0.93834955\n",
      "0.6996768\n",
      "detected:  Elon Musk ( 0.6643489 )\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "0.6550996\n",
      "0.91666096\n",
      "0.69523764\n",
      "detected:  Elon Musk ( 0.6550996 )\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "0.6548849\n",
      "0.93107504\n",
      "0.70171964\n",
      "detected:  Elon Musk ( 0.6548849 )\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "0.6758556\n",
      "0.9188463\n",
      "0.7052387\n",
      "detected:  Elon Musk ( 0.6758556 )\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "0.6512808\n",
      "0.93059826\n",
      "0.7018178\n",
      "detected:  Elon Musk ( 0.6512808 )\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "0.66016895\n",
      "0.9300792\n",
      "0.69575053\n",
      "detected:  Elon Musk ( 0.66016895 )\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "0.66318184\n",
      "0.93138146\n",
      "0.69570047\n",
      "detected:  Elon Musk ( 0.66318184 )\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "0.65452754\n",
      "0.92440623\n",
      "0.6945017\n",
      "detected:  Elon Musk ( 0.65452754 )\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "0.66661584\n",
      "0.93429106\n",
      "0.7063028\n",
      "detected:  Elon Musk ( 0.66661584 )\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "0.65260565\n",
      "0.9263129\n",
      "0.7028198\n",
      "detected:  Elon Musk ( 0.65260565 )\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "0.6837277\n",
      "0.91968745\n",
      "0.71557635\n",
      "detected:  Elon Musk ( 0.6837277 )\n",
      "1/1 [==============================] - 1s 517ms/step\n",
      "0.6791202\n",
      "0.9436647\n",
      "0.7176866\n",
      "detected:  Elon Musk ( 0.6791202 )\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "0.6637756\n",
      "0.93898326\n",
      "0.7025904\n",
      "detected:  Elon Musk ( 0.6637756 )\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "0.66860276\n",
      "0.9429886\n",
      "0.70411456\n",
      "detected:  Elon Musk ( 0.66860276 )\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "0.6785493\n",
      "0.93694246\n",
      "0.69840676\n",
      "detected:  Elon Musk ( 0.6785493 )\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "0.66477287\n",
      "0.94008887\n",
      "0.7034792\n",
      "detected:  Elon Musk ( 0.66477287 )\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "0.9226482\n",
      "0.8903665\n",
      "0.94040525\n",
      "detected:  Flayson Santos ( 0.8903665 )\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0) #webcam\n",
    "#cap = cv2.VideoCapture(\"C:/Users/Flayson Santos/Dio_MachineLearn/machine_learnig/facil_detection_ofc/database/video/teste.mp4\") #video\n",
    "#cap = cv2.VideoCapture('digite o caminho do caminho do seu video ') #video\n",
    "ret=True\n",
    "while(ret==True):\n",
    "    ret, img = cap.read()\n",
    "    if (ret==True):\n",
    "        img = cv2.resize(img, (int(0.5*img.shape[1]), int(0.5*img.shape[0])), interpolation = cv2.INTER_AREA)\n",
    "        faces = face_cascade.detectMultiScale(img, 1.2, 5)\n",
    "        \n",
    "        for (x,y,w,h) in faces:\n",
    "            if w > 130: #discard small detected faces\n",
    "                cv2.rectangle(img, (x,y), (x+w,y+h), (0, 255, 0), 5) #draw rectangle to main image\n",
    "                \n",
    "                detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "                detected_face = cv2.resize(detected_face, target_size) #resize to 152x152\n",
    "                \n",
    "                img_pixels = image.img_to_array(detected_face)\n",
    "                img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "                img_pixels /= 255\n",
    "                \n",
    "                captured_representation = model.predict(img_pixels)[0]\n",
    "                \n",
    "                distances = []\n",
    "                \n",
    "                for i in employees:\n",
    "                    employee_name = i\n",
    "                    source_representation = employees[i]\n",
    "                    \n",
    "                    distance = findEuclideanDistance(l2_normalize(captured_representation), l2_normalize(source_representation))\n",
    "                    distances.append(distance)\n",
    "                    print(distance)\n",
    "                is_found = False; index = 0\n",
    "                for i in employees:\n",
    "                    employee_name = i\n",
    "                    if index == np.argmin(distances):\n",
    "                        if distances[index] <= 0.99:\n",
    "                            \n",
    "                            print(\"detected: \",employee_name, \"(\",distances[index],\")\")\n",
    "                            #employee_name = employee_name.replace(\"_\", \"\")\n",
    "                            similarity = distances[index]\n",
    "                            \n",
    "                            is_found = True\n",
    "                            \n",
    "                            break\n",
    "                        \n",
    "                    index = index + 1\n",
    "                \n",
    "                if is_found:\n",
    "                    display_img = cv2.imread(\"database/%s.jpg\" % employee_name)\n",
    "                    pivot_img_size = 112\n",
    "                    display_img = cv2.resize(display_img, (pivot_img_size, pivot_img_size))\n",
    "                                    \n",
    "                    try:\n",
    "                        resolution_x = img.shape[1]; resolution_y = img.shape[0]\n",
    "                        \n",
    "                        label = employee_name+\" (\"+\"{0:.2f}\".format(similarity)+\")\"\n",
    "                        \n",
    "                        if y - pivot_img_size > 0 and x + w + pivot_img_size < resolution_x:\n",
    "                            #top right\n",
    "                            img[y - pivot_img_size:y, x+w:x+w+pivot_img_size] = display_img\n",
    "                            cv2.putText(img, label, (x+w, y+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)                    \n",
    "                            \n",
    "                            #connect face and text\n",
    "                            cv2.line(img,(x+int(w/2), y), (x+3*int(w/4), y-int(pivot_img_size/2)),(67,67,67),1)\n",
    "                            cv2.line(img, (x+3*int(w/4), y-int(pivot_img_size/2)), (x+w, y - int(pivot_img_size/2)), (67,67,67),1)\n",
    "                        elif y + h + pivot_img_size < resolution_y and x - pivot_img_size > 0:\n",
    "                            #bottom left\n",
    "                            img[y+h:y+h+pivot_img_size, x-pivot_img_size:x] = display_img\n",
    "                            cv2.putText(img, label, (x - pivot_img_size, y+h-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\n",
    "                            \n",
    "                            #connect face and text\n",
    "                            cv2.line(img,(x+int(w/2), y+h), (x+int(w/2)-int(w/4), y+h+int(pivot_img_size/2)),(67,67,67),1)\n",
    "                            cv2.line(img, (x+int(w/2)-int(w/4), y+h+int(pivot_img_size/2)), (x, y+h+int(pivot_img_size/2)), (67,67,67),1)\n",
    "                            \n",
    "                        elif y - pivot_img_size > 0 and x - pivot_img_size > 0:\n",
    "                            #top left\n",
    "                            img[y-pivot_img_size:y, x-pivot_img_size:x] = display_img\n",
    "                            cv2.putText(img, label, (x - pivot_img_size, y+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\n",
    "                            \n",
    "                            #connect face and text\n",
    "                            cv2.line(img,(x+int(w/2), y), (x+int(w/2)-int(w/4), y-int(pivot_img_size/2)),(67,67,67),1)\n",
    "                            cv2.line(img, (x+int(w/2)-int(w/4), y-int(pivot_img_size/2)), (x, y - int(pivot_img_size/2)), (67,67,67),1)\n",
    "                            \n",
    "                        elif x+w+pivot_img_size < resolution_x and y + h + pivot_img_size < resolution_y:\n",
    "                            #bottom righ\n",
    "                            img[y+h:y+h+pivot_img_size, x+w:x+w+pivot_img_size] = display_img\n",
    "                            cv2.putText(img, label, (x+w, y+h-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (67,67,67), 1)\n",
    "                            \n",
    "                            #connect face and text\n",
    "                            cv2.line(img,(x+int(w/2), y+h), (x+int(w/2)+int(w/4), y+h+int(pivot_img_size/2)),(67,67,67),1)\n",
    "                            cv2.line(img, (x+int(w/2)+int(w/4), y+h+int(pivot_img_size/2)), (x+w, y+h+int(pivot_img_size/2)), (67,67,67),1)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(\"exception occured: \", str(e))\n",
    "                \n",
    "        cv2.imshow('img',img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #press q to quit\n",
    "        break\n",
    "    \n",
    "#kill open cv things        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
